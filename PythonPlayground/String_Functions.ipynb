{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58e48994-3110-4bf3-bc9b-195f92036b52",
   "metadata": {},
   "source": [
    "## findString"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652f8aee-3252-4b7b-a7a7-63ca00288c7a",
   "metadata": {},
   "source": [
    "- Create a function, called findString, that takes a string and a file name as arguments, and prints all lines in the file which contain the specified string (regardless of capitalization).\n",
    "- Create a try and except clause to catch the error where the file name passed into the function is not found and prompt the user to enter the correct file name until successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d66dca5d-94d4-4503-b972-584b46902ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_string(search_for: str, file_name):\n",
    "    count = 0\n",
    "    flag = True\n",
    "    while flag:\n",
    "        try:\n",
    "            with open(file_name, 'r') as f:\n",
    "                my_data = [i.lower() for i in f.readlines()]\n",
    "                for line in my_data:\n",
    "                    if search_for.lower() in line:\n",
    "                        print(line)\n",
    "                        count += 1\n",
    "                        flag = False\n",
    "                if count == 0:\n",
    "                    print(f'{search_for} not found in file.')\n",
    "                    break\n",
    "        except FileNotFoundError as e:\n",
    "            print(f'Error: {e}')\n",
    "            file_name = input('That file does not exist. What is the name of your file? ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e833e66a-c380-464f-a094-f56a8b586a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: [Errno 2] No such file or directory: 'test.txt'\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "That file does not exist. What is the name of your file?  kenobiquotes.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat not found in file.\n"
     ]
    }
   ],
   "source": [
    "find_string('cat', 'test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ec68f9c-b654-465b-b213-46d7c4f3dbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you were my brother, anakin! i loved you!\n",
      "\n",
      "you are a great warrior, anakin. but your need to prove yourself is your undoing. until\n",
      "\n"
     ]
    }
   ],
   "source": [
    "find_string('Anakin', 'kenobiquotes.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a76c11d-566e-49b8-a690-c721d578120a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# could be worth coming back to this one and adding to the function so that it returns the entire quote, not just\n",
    "# the single line, if nothing else as an exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdd78ad-1170-4d2e-a6b3-4a9cb01aeccf",
   "metadata": {},
   "source": [
    "## wrapLines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf43181a-67ed-46a0-9986-293f5f9f445a",
   "metadata": {},
   "source": [
    "- Write a function, called wrapLines, that takes a file name and an integer of length k. The function wraps the lines longer than width k by splitting them into lines of length less than or equal to k, just like resizing a text editor window.\n",
    "- Make sure not to break in the middle of a word.\n",
    "- If the word is longer than k, you may split it using a hyphen or leaving the entire word on a single line.\n",
    "- Create a try and except clause to catch the error where the file name passed into the function is not found and prompt the user to enter the correct file name until successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "015a9385-9ce0-4d20-bad8-041bbc692873",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_lines(k: int, file_name):\n",
    "    flag = True\n",
    "    string_to_write = []\n",
    "    temp_leng = 0\n",
    "    new_line = []\n",
    "    while flag:\n",
    "        try:\n",
    "            with open(file_name, 'r') as f:\n",
    "                # read file into a list\n",
    "                rl = f.readlines()\n",
    "                # remove newlines\n",
    "                line_list = [i.replace('\\n', '') for i in rl]\n",
    "                # join lines together into a single list of all words\n",
    "                word_list = ' '.join(line_list).split()\n",
    "                #print(line_list)\n",
    "                for word in word_list:\n",
    "                    #print(line)\n",
    "                    if (temp_leng + len(word) <= k):\n",
    "                        new_line.append(word)\n",
    "                        temp_leng += len(word) + 1\n",
    "                    else:\n",
    "                        new_line = ' '.join(new_line)\n",
    "                        string_to_write.append(new_line + '\\n')\n",
    "                        new_line = [word]\n",
    "                        temp_leng = len(word) + 1\n",
    "                new_line = ' '.join(new_line)\n",
    "                string_to_write.append(new_line + '\\n')\n",
    "            flag = False\n",
    "\n",
    "        except FileNotFoundError as e:\n",
    "            print(f'Error: {e}')\n",
    "            file_name = input('That file does not exist. What is the name of your file? ')\n",
    "    with open('wrapped.txt', 'w') as f:\n",
    "        for i in string_to_write:\n",
    "            f.write(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3f0ee6b7-77a0-4fa9-b9a5-4afca65c20e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap_lines(20, 'kenobiquotes.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dab42057-6ca1-487d-9cd7-98fc94bc79a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: [Errno 2] No such file or directory: 'test.txt'\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "That file does not exist. What is the name of your file?  kenobiquotes.txt\n"
     ]
    }
   ],
   "source": [
    "wrap_lines(7, 'test.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28175eb-e342-4e7d-a3cc-ff27f07e0e1b",
   "metadata": {},
   "source": [
    "## allAnagrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000b9962-dcf5-42ec-89fc-9c5056a95391",
   "metadata": {},
   "source": [
    "Create a function, called allAnagrams, find all anagrams in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6b813f4e-b711-4bc2-855d-74cff7aa1d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_anagrams(file_name):\n",
    "    anagrams = set()\n",
    "    \n",
    "    with open(file_name, 'r') as f:\n",
    "        # read lines from file into a list\n",
    "        lines = f.readlines()\n",
    "        # process (lowercase and remove newlines) and add length for each word, to create a tuple w/each word and its length\n",
    "        lines = [(i.lower().replace('\\n', ''), len(i.lower().replace('\\n', ''))) for i in lines]\n",
    "        #print(lines)\n",
    "\n",
    "        # create empty dictionary\n",
    "        word_dict = {}\n",
    "        for word_tuple in lines:\n",
    "            if (word_tuple[1] in word_dict):\n",
    "                word_dict[word_tuple[1]].add(word_tuple[0])\n",
    "            else:\n",
    "                word_dict[word_tuple[1]] = set([word_tuple[0]])\n",
    "\n",
    "    # create empty set to keep track of indexes not needed to search\n",
    "    idx_to_skip = set()\n",
    "\n",
    "    # step through the dictionary values\n",
    "    for key, value in word_dict.items():\n",
    "        value = list(value)\n",
    "        # if the length of the word == 1 or the list of words = 1, skip\n",
    "        if (key == 1 or len(value) == 1):\n",
    "            continue\n",
    "        else:\n",
    "            for idx, word in enumerate(value):\n",
    "                if idx in idx_to_skip:\n",
    "                    continue\n",
    "                for next_word in value[idx + 1: len(value)]:\n",
    "                    if (next_word in anagrams):\n",
    "                        continue\n",
    "                    if ''.join(sorted(word)) == ''.join(sorted(next_word)):\n",
    "                        anagrams.add(word)\n",
    "                        anagrams.add(next_word)\n",
    "                        idx_to_skip.union(set([idx, value.index(next_word)]))\n",
    "\n",
    "    return anagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ea4aa39c-6024-49b6-8cc3-3bf61e7e82f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "anagrams = all_anagrams('anagrams.txt')\n",
    "# this particular file run through should return 26 anagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f1de7f99-4cf9-4269-a1bb-f93cddce87fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'act',\n",
       "  'angel',\n",
       "  'arc',\n",
       "  'below',\n",
       "  'bored',\n",
       "  'brag',\n",
       "  'car',\n",
       "  'cat',\n",
       "  'cheap',\n",
       "  'chin',\n",
       "  'cider',\n",
       "  'cried',\n",
       "  'dreads',\n",
       "  'dusty',\n",
       "  'elbow',\n",
       "  'glean',\n",
       "  'grab',\n",
       "  'inch',\n",
       "  'night',\n",
       "  'parsley',\n",
       "  'peach',\n",
       "  'players',\n",
       "  'robed',\n",
       "  'sadder',\n",
       "  'study',\n",
       "  'thing'},\n",
       " 26)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anagrams, len(anagrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d60737c-02cd-4589-a004-495301d6dc96",
   "metadata": {},
   "source": [
    "## Breast Cancer Data Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1147695a-3b06-476a-9e42-b641b573f411",
   "metadata": {},
   "source": [
    "Read in a file on breast cancer data and filter it based on a new type of classification method. Compare original classification to new classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "77ee848d-d6cf-4478-ad25-4ff44fb9a07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the given data, and split it into four different files based on the given constraints for a new classification method\n",
    "def tumor_classification(input_file: str):\n",
    "\n",
    "    # set constants that keep the index position of data\n",
    "    ID = 0\n",
    "    DIAGNOSIS = 1\n",
    "    RADIUS = 2\n",
    "    TEXTURE = 3\n",
    "    PERIM = 4\n",
    "    AREA = 5\n",
    "    orig_m = []\n",
    "    \n",
    "    # create a list of lists to hold later processed data\n",
    "    dims = [\n",
    "        [],\n",
    "        [],\n",
    "        [],\n",
    "        [],\n",
    "    ]\n",
    "\n",
    "    # list of filenames to be used later when writing to files\n",
    "    filenames = [\n",
    "        \"q3_gte_13\",\n",
    "        \"q4_gte_18\",\n",
    "        \"q5_gte_85\",\n",
    "        \"q6_gte_500\",\n",
    "    ]\n",
    "\n",
    "    with open(input_file) as f:\n",
    "        header = f.readline()\n",
    "        for line in f:\n",
    "            split_line = line.split(\",\")\n",
    "            # append the data depending on given conditions to the list of lists created above\n",
    "            if float(split_line[RADIUS]) >= 13:\n",
    "                dims[0].append(\n",
    "                    [split_line[ID], split_line[DIAGNOSIS], split_line[RADIUS]]\n",
    "                )\n",
    "            if float(split_line[TEXTURE]) >= 18:\n",
    "                dims[1].append(\n",
    "                    [split_line[ID], split_line[DIAGNOSIS], split_line[TEXTURE]]\n",
    "                )\n",
    "            if float(split_line[PERIM]) >= 85:\n",
    "                dims[2].append(\n",
    "                    [split_line[ID], split_line[DIAGNOSIS], split_line[PERIM]]\n",
    "                )\n",
    "            if float(split_line[AREA]) >= 500:\n",
    "                dims[3].append(\n",
    "                    [split_line[ID], split_line[DIAGNOSIS], split_line[AREA]]\n",
    "                )\n",
    "            if split_line[DIAGNOSIS].lower() == \"m\":\n",
    "                # keep the original id's tagged as class 'm'\n",
    "                orig_m.append(split_line[ID])\n",
    "\n",
    "    # write out to the four files\n",
    "    for idx, filename in enumerate(filenames):\n",
    "        filename += \".csv\"\n",
    "        with open(filename, \"w\") as f:\n",
    "            for item in dims[idx]:\n",
    "                f.write(\",\".join(item) + \"\\n\")\n",
    "\n",
    "    # intersect the id's from each list and write to a unioned_file\n",
    "    new_result = set([i[ID] for i in dims[0]])\n",
    "    for dim in dims[1:]:\n",
    "        new_result = new_result.intersection(set([i[ID] for i in dim]))\n",
    "        \n",
    "    subset_m_result = set()\n",
    "    for dim in dims:\n",
    "        subset_m_result = subset_m_result.union(set([i[ID] for i in dim if i[DIAGNOSIS].lower() == 'm']))\n",
    "\n",
    "    # sort the new classifications compared to their original comparisions and write out to new files\n",
    "    same = [i for i in subset_m_result if i in new_result]\n",
    "    diff = [i for i in orig_m if i not in new_result]\n",
    "    diff = sorted(diff)\n",
    "\n",
    "    with open('diff.csv', 'w') as f:\n",
    "        for i in diff:\n",
    "            f.write(i + '\\n')\n",
    "\n",
    "    with open('same.csv', 'w') as f:\n",
    "        for i in same:\n",
    "            f.write(i + '\\n')\n",
    "\n",
    "    with open('orig_m.csv', 'w') as f:\n",
    "        for i in orig_m:\n",
    "            f.write(i + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "869a1564-ed53-4edb-9d90-c0e8514d09e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tumor_classification('breastCancerDataReducedDimensions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3ba6c946-1935-4186-816b-7face3827ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see output CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69ebb33-d1c2-44a7-81b5-64cc26a5b3e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
